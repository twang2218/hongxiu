作为一个学术论文资深编辑，请根据给出的论文图片信息，帮忙修订所提供的 JSON 格式的论文总结。
内容有如下要求：
1. 请根据图片对于理解论文的重要性进行排序，将最重要的图片插入到summary中对应部分的前面。
2. 请注意提供的figure类型，请只插入图片，而不要插入表格。
3. 图片插入的格式如下，假设图片链接为 figures/abc.jpg，如果需要插入的段落是 list 中的某个元素，则在该元素前面插入一项同级元素:
  "IMAGE|path/to/abc.jpg"
  如果需要插入的段落是 dict 中的某个键值对，则在该键值对前面插入同级键值对:
  "IMAGE": "path/to/abc.jpg"
4. 插入时，请注意 JSON 格式的正确性，插入后的格式应符合JSON格式要求。
5. 请只生成 JSON 内容，不需要包含任何额外的说明或解释，也不需要包含 markdown json 代码段标记。
6. 示例：如：
  假如你发现所提供的图片 aaa/bbb/ccc.png 对于所提供的 JSON 格式的论文总结中的「研究方法」中的「下一个句子预测」部分非常重要，请将该图片链接插入到「下一个句子预测」部分的前面，

  原始的 JSON 格式的论文总结相关部分如下：

    ...
    {
      "研究方法": {
        "介绍": "BERT模型通过一种名为‘掩码语言模型’(MLM)的预训练目标来克服传统语言模型的单向性限制，同时引入‘下一个句子预测’(NSP)任务以捕捉句子对之间的关系。",
        "具体": {
          "掩码语言模型(MLM)": "在输入序列中随机掩盖一定比例的单词，并基于上下文预测这些单词，允许模型在上下文中学习双向信息。",
          "下一个句子预测(NSP)": "通过选择连续的句子或随机句子，训练模型理解句子间的关系，从而提高问答和自然语言推理的能力。"
        }
      }
    }
    ...

  修订后的 JSON 格式的论文总结相关部分如下：

    ...
    {
      "研究方法": {
        "介绍": "BERT模型通过一种名为‘掩码语言模型’(MLM)的预训练目标来克服传统语言模型的单向性限制，同时引入‘下一个句子预测’(NSP)任务以捕捉句子对之间的关系。",
        "具体": {
          "掩码语言模型(MLM)": "在输入序列中随机掩盖一定比例的单词，并基于上下文预测这些单词，允许模型在上下文中学习双向信息。",
          "IMAGE": "aaa/bbb/ccc.png",
          "下一个句子预测(NSP)": "通过选择连续的句子或随机句子，训练模型理解句子间的关系，从而提高问答和自然语言推理的能力。"
        }
      }
    }
    ...
7. 请检查论文总结 JSON 中， summary 下的结构，如有不应包含的内容，比如并无实验设计，但是 summary 中包含了「实验设计」，请删除这部分内容。
